= Topics and Partitions
include::_attributes.adoc[]

Apache Kafka is a distributed robust publish/subscribe system.
It can act as a message queue but it offers two major advantages over traditional pub/sub systems.

. Storing records with Fault Tolerance.
. Processing data streams as they occur in near real-time instead of in large batches.

image::cbp.png[]

Notice in the next figure, the difference in how the entities are stored in a Kafka topic VS how they are stored in an RDBMS.
Events are always stored as they are appended in the log and they are never overridden, whereas in an RDBMS, you are storing a snapshot of an entity and when you update an entity you are modifying the original record "in place".
 
image::dbvsevent.png[]

Other differences are:

* Real Time vs batch processing
* Distributed / Fault Tolerant vs none-distributed / single point of failure

[#topics]
== What are Topics?

A topic is a collection of events that are persisted to disk. Topics support the concept of data retention such that events can be appended and kept for longer periods (e.g. days/weeks/months) or only be stored short-lived (e.g. minutes/hours)

image::cbtp.png[]

[#partitions]
== What are Partitions?

A topic is further divided into multipe partitions - at least one, but can be 10s or 100s - to improve the performance in cases of heavy load. The number of topic partitions defines the maximum parallelism a single consuming application consisting of multiple instances can achive for processing the stored events.

The partitions of a topic are distributed (i.e. replicated) across all the Kafka brokers to achieve fault-tolerance and to increase the parallelism when working with topics.

The sum of all events in all the topic's partitions is what conforms a topic as a whole.

image::pbtpc.png[]

Topic partitions can be configured to be replicated across different Kafka brokers.

image::bp.png[]

For each replicated topic partition one of the partitions is the designated leader.
Usually all events are produced to and consumed from the leader, and the other replicas stay in sync with the leader. If the leader becomes unavailable, one of the synced replicas becomes the new leader.

[IMPORTANT]
====
Starting with Apache Kafka 2.4.0 a consumer also can be configured to process messages from other replicas even though they aren't leaders.

.Red Partitions are the leaders
image::After-KIP-392.png[]

Also a `ReplicaSelector` interface is provided so you can implement a custom selector of the replica from where messages are consumed.
====

[#messages]
== What are Messages?

A message (also known as a Kafka record) is a key/value pair that is stored inside a topic partition. Message are persisted and durable in accordance with the configured retention settings for a topic.

A message is typically a "smallish" chunk of data consisting of its key (optional) to identify the message. If the key is present it is used by default to decide in which topic partition a message should get stored. The value represents the payload of the message. Both, keys and values, can support different serialization formats such as Avro, Json or Protobuf. Kafka brokers themselves don't care about the data format at all and only store sequences of bytes.

Additionally, each message contains metadata such as a timestamp attribute that is either set by the producer at creation time or by the broker on insertion time.

IMPORTANT: Although you can configure Apache Kafka to work with larger messages, the default maximum size is `1 MB`. Note that the Kafka record size is ideally within that limit and is often around a few 100 KBs.

image::pkp.png[]

[#topic-creation]
== Topic Creation

Apache Kafka can be configured to auto-create topics which means it is possible to publish a message to a non-existant topic that will be created on the fly. However, it is not recommended to work with topic auto-creation in production scenarios.

You can also use tools such as `kafka-topic.sh` to pre-create your topic(s) manually.

include::partial$docker-exec.adoc[]

Inside the container, create a topic with the name `songs` having a single partition and only one replica:

[.console-input]
[source, bash-shell]
----
./bin/kafka-topics.sh --create --bootstrap-server kafka:9092 --replication-factor 1 --partitions 1 --topic songs
----
[.console-output]
[source,bash,subs="+macros,+attributes"]
----
Created topic songs.
----
[.console-input]
[source, bash-shell]
----
./bin/kafka-topics.sh --list --bootstrap-server kafka:9092
----
[.console-output]
[source,bash,subs="+macros,+attributes"]
----
songs
----

Now that you have validated the topic exists you can run `exit` to leave the container

[.console-input]
[source, bash-shell]
----
exit
----

[#topic-info]
== Get Topic information

You can also get the topic information by using `kcat` from your host OS:

[tabs]
====
kcat::
+
--
[.console-input]
[source, bash-shell]
----
kcat -b localhost:29092 -L
----
[.console-output]
[source, bash-shell]
----
Metadata for all topics (from broker 1: localhost:29092/1):
 1 brokers:
  broker 1 at localhost:29092 (controller)
 1 topics:
  topic "songs" with 1 partitions:
    partition 0, leader 1, replicas: 1, isrs: 1
----
--
kcat in Podman::
+
--
[.console-input]
[source, bash-shell]
----
podman run --rm -it --network=kafka-tutorial edenhill/kcat:1.7.1 kcat -b kafka:9092 -L
----
[.console-output]
[source, bash-shell]
----
Metadata for all topics (from broker 1: kafka:9092/1):
 1 brokers:
  broker 1 at kafka:9092 (controller)
 1 topics:
  topic "songs" with 1 partitions:
    partition 0, leader 1, replicas: 1, isrs: 1
----
--
kcat in Docker::
+
--
[.console-input]
[source, bash-shell]
----
docker run --rm -it --network=kafka-tutorial edenhill/kcat:1.7.1 kcat -b kafka:9092 -L
----
[.console-output]
[source, bash-shell]
----
Metadata for all topics (from broker 1: kafka:9092/1):
 1 brokers:
  broker 1 at kafka:9092 (controller)
 1 topics:
  topic "songs" with 1 partitions:
    partition 0, leader 1, replicas: 1, isrs: 1
----
--
====
