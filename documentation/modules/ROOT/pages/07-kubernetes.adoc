= Kafka in Kubernetes
include::_attributes.adoc[]
include::https://raw.githubusercontent.com/redhat-developer-demos/rhd-tutorial-common/master/versions.adoc[]

Kubernetes is an open source container orchestration platform that automates many of the manual processes involved in deploying, managing, and scaling containerized applications.

Kubernetes is an ideal platform for hosting cloud-native applications that require rapid scaling, like real-time data streaming through Apache Kafka.

But deploying a Kafka cluster with Zookeeper and more than one broker, it is not an easy task and https://strimzi.io/[Strimzi] makes this task a simple task.

[#kubernetes]
== Kubernetes

To run this part you need a Kubernetes cluster running.

[#install-minikube]
=== Install Minikube

include::https://raw.githubusercontent.com/redhat-developer-demos/rhd-tutorial-common/master/install-minikube.adoc[]

[#start-kubernetes]
=== Start Kubernetes

The following section shows how to start Kubernetes with required configurations:

:profile: kafka
include::https://raw.githubusercontent.com/redhat-developer-demos/rhd-tutorial-common/master/kubernetes-setup.adoc[]

[#strimzi]
== Strimzi

Strimzi provides a way to run an Apache Kafka cluster on Kubernetes in various deployment configurations.

Some of the features of Strimzi are:

Secure by Default:: TLS and SCRAM-SHA supported. Automated Certificate Management.
Simple yet Configurable:: NodePort, Load balancer, and Ingress options. Rack awareness for HA. Use dedicated nodes for Kafka.
Kubernetes-Native Experience:: `kubectl get kafka`. Operator Based. Manage Kafka using gitops.

[#installing-crds]
=== Installation of Strimzi Operator

Strimzi uses Kubernetes operators to manage the Kafka cluster.
To install the Strimzi operator you need to run the following command:


[tabs]
====
Minikube::
+
--
[.console-input]
[source, bash-shell]
----
kubectl apply -f 'https://strimzi.io/install/latest?namespace=default' -n default 
----

[.console-output]
[source, bash-shell,subs="+macros,+attributes"]
----
customresourcedefinition.apiextensions.k8s.io/kafkas.kafka.strimzi.io created
rolebinding.rbac.authorization.k8s.io/strimzi-cluster-operator-entity-operator-delegation created
clusterrolebinding.rbac.authorization.k8s.io/strimzi-cluster-operator created
rolebinding.rbac.authorization.k8s.io/strimzi-cluster-operator-topic-operator-delegation created
customresourcedefinition.apiextensions.k8s.io/kafkausers.kafka.strimzi.io created
customresourcedefinition.apiextensions.k8s.io/kafkamirrormaker2s.kafka.strimzi.io created
clusterrole.rbac.authorization.k8s.io/strimzi-entity-operator created
clusterrole.rbac.authorization.k8s.io/strimzi-cluster-operator-global created
clusterrolebinding.rbac.authorization.k8s.io/strimzi-cluster-operator-kafka-broker-delegation created
rolebinding.rbac.authorization.k8s.io/strimzi-cluster-operator created
clusterrole.rbac.authorization.k8s.io/strimzi-cluster-operator-namespaced created
clusterrole.rbac.authorization.k8s.io/strimzi-topic-operator created
serviceaccount/strimzi-cluster-operator created
clusterrole.rbac.authorization.k8s.io/strimzi-kafka-broker created
customresourcedefinition.apiextensions.k8s.io/kafkatopics.kafka.strimzi.io created
customresourcedefinition.apiextensions.k8s.io/kafkabridges.kafka.strimzi.io created
deployment.apps/strimzi-cluster-operator created
customresourcedefinition.apiextensions.k8s.io/kafkaconnectors.kafka.strimzi.io created
customresourcedefinition.apiextensions.k8s.io/kafkaconnects2is.kafka.strimzi.io created
customresourcedefinition.apiextensions.k8s.io/kafkaconnects.kafka.strimzi.io created
customresourcedefinition.apiextensions.k8s.io/kafkamirrormakers.kafka.strimzi.io created
----

[.console-input]
[source, bash-shell]
----
kubectl get pods
----

[.console-output]
[source, bash-shell,subs="+macros,+attributes"]
----
NAME                                          READY   STATUS    RESTARTS   AGE
strimzi-cluster-operator-59b99fc7cf-h4kf8     1/1     Running   0          6m53s
----
--
OpenShift::
+
--
To install Kafka in OpenShift, you can go to menu:Operators[OperatorHub] and search for `Kafka`.
Then select the `Red Hat Integration - AMQ Streams` and install it.

image::amqstreams.png[]
--
====

Check that everything has been installed by running the following commands:

[.console-input]
[source, bash-shell]
----
kubectl get crds | grep kafka
----

[.console-output]
[source, bash-shell,subs="+macros,+attributes"]
----
NAME                                  CREATED AT
kafkabridges.kafka.strimzi.io         2020-05-07T07:50:38Z
kafkaconnectors.kafka.strimzi.io      2020-05-07T07:50:38Z
kafkaconnects.kafka.strimzi.io        2020-05-07T07:50:38Z
kafkaconnects2is.kafka.strimzi.io     2020-05-07T07:50:38Z
kafkamirrormaker2s.kafka.strimzi.io   2020-05-07T07:50:37Z
kafkamirrormakers.kafka.strimzi.io    2020-05-07T07:50:39Z
kafkas.kafka.strimzi.io               2020-05-07T07:50:37Z
kafkatopics.kafka.strimzi.io          2020-05-07T07:50:38Z
kafkausers.kafka.strimzi.io           2020-05-07T07:50:37Z
----

[#deploy-kafka]
=== Deploying Kafka Cluster

To deploy the cluster, you need to create a Kafka resource file using the Kafka Custom Resource Definition (_CRD_).

In this case, you are going to deploy a Kafka cluster with 3 instances and ephemeral storage.

The file you are going to apply is the next one:

[.console-input]
[source, bash-shell]
----
include::https://strimzi.io/examples/latest/kafka/kafka-ephemeral.yaml[]
----

Notice how simple it is to deploy a Kafka cluster in Kubernetes, you just need a few YAML lines.
Run the following command to deploy Kafka:

[.console-input]
[source, bash-shell,subs="+macros,+attributes"]
----
kubectl apply -f https://strimzi.io/examples/latest/kafka/kafka-ephemeral.yaml -n default
----

[.console-output]
[source, bash-shell,subs="+macros,+attributes"]
----
kafka.kafka.strimzi.io/my-cluster created
----

To wait until Kafka cluster is up and running, you can run the following comamnd:

[.console-input]
[source, bash-shell]
----
kubectl wait kafka/my-cluster --for=condition=Ready --timeout=300s -n default
----

[.console-output]
[source, bash-shell,subs="+macros,+attributes"]
----
kafka.kafka.strimzi.io/my-cluster condition met
----

After that, you should have Kafka pods and services up and running:

[.console-input]
[source, bash-shell,subs="+macros,+attributes"]
----
kubectl get pods
----

[.console-output]
[source, bash-shell,subs="+macros,+attributes"]
----
NAME                                          READY   STATUS    RESTARTS   AGE
my-cluster-entity-operator-77b5dd5594-hl7cf   3/3     Running   0          44s
my-cluster-kafka-0                            2/2     Running   0          70s
my-cluster-kafka-1                            2/2     Running   0          70s
my-cluster-kafka-2                            2/2     Running   0          70s
my-cluster-zookeeper-0                        2/2     Running   0          108s
my-cluster-zookeeper-1                        2/2     Running   0          108s
my-cluster-zookeeper-2                        2/2     Running   0          108s
strimzi-cluster-operator-59b99fc7cf-h4kf8     1/1     Running   0          6m53s
----

And services:

[.console-input]
[source, bash-shell]
----
kubectl get services
----

[.console-output]
[source, bash-shell,subs="+macros,+attributes"]
----
NAME                          TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)                      AGE
kubernetes                    ClusterIP   10.96.0.1        <none>        443/TCP                      11m
my-cluster-kafka-bootstrap    ClusterIP   10.103.67.179    <none>        9091/TCP,9092/TCP,9093/TCP   92s
my-cluster-kafka-brokers      ClusterIP   None             <none>        9091/TCP,9092/TCP,9093/TCP   92s
my-cluster-zookeeper-client   ClusterIP   10.101.161.217   <none>        2181/TCP                     2m11s
my-cluster-zookeeper-nodes    ClusterIP   None             <none>        2181/TCP,2888/TCP,3888/TCP   2m11s
----

[#deploy-service-strimzi]
== Deploying Services

Let's deploy the example done at <<Developing Consumers and Producers in Java>>, but in Kubernetes instead of Docker.
At this time, Quarkus version of the `song` - `song-indexer` application is deployed.

[#kubernetes-song-app]
=== Deploy Song Service

To deploy the Song Service go to:

[.console-input]
[source, bash-shell]
----
cd $TUTORIAL_HOME/apps/song-app/quarkus/song-app
----

And use `kubectl` to deploy the service:

[.console-input]
[source, bash-shell]
----
kubectl apply -f src/main/kubernetes/kubernetes.yml
----

[.console-output]
[source, bash-shell,subs="+macros,+attributes"]
----
serviceaccount/kafka-tutorial-song-app created
service/kafka-tutorial-song-app created
deployment.apps/kafka-tutorial-song-app created
----

Verify that the service has been deployed correctly:

[.console-input]
[source, bash-shell]
----
kubectl get pods
----

[.console-output]
[source, bash-shell,subs="+macros,+attributes"]
----
kafka-tutorial-song-app-84f8476bc8-vhr4k           1/1     Running   0          8m53s
my-cluster-entity-operator-77b5dd5594-hl7cf        3/3     Running   3          8h
my-cluster-kafka-0                                 2/2     Running   3          8h
my-cluster-kafka-1                                 2/2     Running   3          8h
my-cluster-kafka-2                                 2/2     Running   3          8h
my-cluster-zookeeper-0                             2/2     Running   2          8h
my-cluster-zookeeper-1                             2/2     Running   2          8h
my-cluster-zookeeper-2                             2/2     Running   2          8h
strimzi-cluster-operator-59b99fc7cf-h4kf8          1/1     Running   1          8h
----

[#kubernetes-song-indexer-app]
=== Deploy Song Indexer Service

To deploy the Song Indexer Service go to:

[.console-input]
[source, bash-shell]
----
cd $TUTORIAL_HOME/apps/song-indexer-app/quarkus/song-indexer-app
----

And use `kubectl` to deploy the service:

[.console-input]
[source, bash-shell]
----
kubectl apply -f src/main/kubernetes/kubernetes.yml
----

[.console-output]
[source, bash-shell,subs="+macros,+attributes"]
----
serviceaccount/kafka-tutorial-song-indexer-app created
service/kafka-tutorial-song-indexer-app created
deployment.apps/kafka-tutorial-song-indexer-app created
----

Verify that the service has been deployed correctly:

[.console-input]
[source, bash-shell]
----
kubetl get pods
----

[.console-output]
[source, bash-shell,subs="+macros,+attributes"]
----
NAME                                               READY   STATUS    RESTARTS   AGE
kafka-tutorial-song-app-84f8476bc8-vhr4k           1/1     Running   0          8m53s
kafka-tutorial-song-indexer-app-58fbc7d6fd-979zw   1/1     Running   0          4m6s
my-cluster-entity-operator-77b5dd5594-hl7cf        3/3     Running   3          8h
my-cluster-kafka-0                                 2/2     Running   3          8h
my-cluster-kafka-1                                 2/2     Running   3          8h
my-cluster-kafka-2                                 2/2     Running   3          8h
my-cluster-zookeeper-0                             2/2     Running   2          8h
my-cluster-zookeeper-1                             2/2     Running   2          8h
my-cluster-zookeeper-2                             2/2     Running   2          8h
strimzi-cluster-operator-59b99fc7cf-h4kf8          1/1     Running   1          8h
----

[#kubernetes-testing]
=== Test It

Let's test that it works as expected.

The first thing that you need to know is the exposed port of each of the services.

[.console-input]
[source, bash-shell]
----
kubectl get services
----

[.console-output]
[source, bash-shell,subs="+macros,+attributes"]
----
NAME                              TYPE           CLUSTER-IP       EXTERNAL-IP   PORT(S)                      AGE
kafka-tutorial-song-app           LoadBalancer   10.99.68.119     <pending>     8080:31834/TCP               5m15s
kafka-tutorial-song-indexer-app   LoadBalancer   10.103.172.33    <pending>     8080:30581/TCP               28s
kubernetes                        ClusterIP      10.96.0.1        <none>        443/TCP                      8h
my-cluster-kafka-bootstrap        ClusterIP      10.103.67.179    <none>        9091/TCP,9092/TCP,9093/TCP   8h
my-cluster-kafka-brokers          ClusterIP      None             <none>        9091/TCP,9092/TCP,9093/TCP   8h
my-cluster-zookeeper-client       ClusterIP      10.101.161.217   <none>        2181/TCP                     8h
my-cluster-zookeeper-nodes        ClusterIP      None             <none>        2181/TCP,2888/TCP,3888/TCP   8h
----

In this specific case, `kafka-tutorial-song-app` port is `31834` and `kafka-tutorial-song-indexer-app` is `30581` but this is going to change every time you deploy these services.

Then you need the IP to connect.
This IP is the minikube IP and it is known by running the following command:

[.console-input]
[source, bash-shell]
----
minikube ip -p kafka
----

[.console-output]
[source, bash-shell,subs="+macros,+attributes"]
----
192.168.99.107
----

Open 2 terminal windows, one for populating songs, and another one to get the result from the indexer service.

In the terminal 1 run the following command:

[.console-input]
[source, bash-shell]
----
http GET 192.168.99.107:30581/events --stream --timeout=600
----

[.console-output]
[source, bash-shell,subs="+macros,+attributes"]
----
HTTP/1.1 200 OK
Content-Type: text/event-stream
transfer-encoding: chunked
----

In the terminal 2 run the following command:

[.console-input]
[source, bash-shell]
----
http POST 192.168.99.107:31834/songs id=107 name=Portals author='Alan Silvestri'
----

Inspect the output of terminal 2, to check that the song has been processed by indexer service.

[.console-output]
[source, bash-shell,subs="+macros,+attributes"]
----
data: {"author":"Alan Silvestri","id":107,"name":"Portals","op":"ADD"}
----

[#kubernetes-cleanup]
== Clean Up

To clean the namespace run:

[.console-input]
[source, bash-shell]
----
kubectl delete all --all
----
